{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import các thư viện\n",
    "import requests\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "from dateutil import relativedelta\n",
    "import sys\n",
    "import os\n",
    "import pygsheets\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pygsheets\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get old data\n"
     ]
    }
   ],
   "source": [
    "#Mở gg sheet để lấy ra dữ liệu cũ\n",
    "client = pygsheets.authorize(service_file = \"/Users/genkin/Downloads/MAIDO BOT/maido-agency-e7cc6f08cb95.json\")\n",
    "sh = client.open('(MD-GK) RECRUITING MANAGEMENT')\n",
    "wks = sh.worksheet_by_title('New CV')\n",
    "recruitment_data = wks.get_as_df()\n",
    "print('Get old data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cài đặt option cho Chrome driver -> mở Chrome -> Mở web \n",
    "options = Options()\n",
    "options.add_experimental_option('prefs', {\n",
    "\"download.default_directory\": r\"/Users/genkin/Downloads/CV_CRAWL_BOT/Job_Application_Crawl-main/CV_downloaded\", #Change default directory for downloads\n",
    "\"download.prompt_for_download\": False, #To auto download the file\n",
    "\"download.directory_upgrade\": True,\n",
    "\"plugins.always_open_pdf_externally\": True #It will not show PDF directly in chrome\n",
    "})\n",
    "driver = webdriver.Chrome(options = options)\n",
    "driver.get('https://careerbuilder.vn/vi/employers/hrcentral/manageresume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login\n"
     ]
    }
   ],
   "source": [
    "#Tìm ô input tài khoản, mật khẩu và truyền tài khoản mật khẩu từ file login.json vào. Sau đó clink vào nút đăng nhập.\n",
    "f = open('login.json')\n",
    "\n",
    "data = json.load(f)\n",
    "\n",
    "username = data['username']\n",
    "password = data['password']\n",
    "\n",
    "user_field = driver.find_element(By.XPATH, '//*[@id=\"frmLogin\"]/div[1]/div[2]/input')\n",
    "user_field.send_keys(username)\n",
    "time.sleep(5)\n",
    "\n",
    "pass_field = driver.find_element(By.XPATH, '//*[@id=\"frmLogin\"]/div[2]/div[2]/input')\n",
    "pass_field.send_keys(password)\n",
    "time.sleep(5)\n",
    "\n",
    "login_field = driver.find_element(By.XPATH, '//*[@id=\"frmLogin\"]/div[3]/div/button')\n",
    "login_field.click()\n",
    "time.sleep(5)\n",
    "print('Login')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lặp qua các job để lấy về đường link -> id của job\n",
    "job_link = []\n",
    "\n",
    "for i in range(2,100):\n",
    "    # Bắt đầu từ job thứ 2\n",
    "    try:\n",
    "        job_input = driver.find_element(By.XPATH,'//*[@id=\"select-folder\"]')\n",
    "        job_input.click()\n",
    "        job =  driver.find_element(By.XPATH, f'//*[@id=\"select-folder\"]/option[{i}]')\n",
    "        job.click()\n",
    "        url = driver.current_url\n",
    "        index = str(url).find('/*/0/0/*/*/7/2/6/2/0/desc/hr.1661228713/1')\n",
    "        id = str(url)[index-8:index]\n",
    "        link = r'https://careerbuilder.vn/vi/employers/hrcentral/manageresume/1/' + id +r'/*/0/0/03-02-2023/*/7/2/6/2/0/desc/hr.1661228713/1'\n",
    "        job_link.append(link)\n",
    "    \n",
    "    #Khi đã hết job thì quay về job đầu tiên\n",
    "    except:\n",
    "        job_input = driver.find_element(By.XPATH,'//*[@id=\"select-folder\"]')\n",
    "        job_input.click()\n",
    "        job =  driver.find_element(By.XPATH, f'//*[@id=\"select-folder\"]/option[1]')\n",
    "        job.click()\n",
    "        url = driver.current_url\n",
    "        index = str(url).find('/*/0/0/*/*/7/2/6/2/0/desc/hr.1661228713/1')\n",
    "        id = str(url)[index-8:index]\n",
    "        link = r'https://careerbuilder.vn/vi/employers/hrcentral/manageresume/1/' + id +r'/*/0/0/03-02-2023/*/7/2/6/2/0/desc/hr.1661228713/1'\n",
    "        job_link.append(link)\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get candidate url: 37\n"
     ]
    }
   ],
   "source": [
    "#Lặp qua từng đường link của job lấy về thông tin ứng viên\n",
    "candidate_url = []\n",
    "\n",
    "for link in job_link:\n",
    "\n",
    "    driver.get(link)\n",
    "    \n",
    "    #Lấy ra có bao nhiêu ứng viên\n",
    "    page_navi = driver.find_element(By.XPATH, f'//*[@id=\"tab-1\"]/div/div[2]/div[2]/div/p').text\n",
    "    if page_navi != \"\":\n",
    "        no_candidate = int(page_navi.split(' ')[6])\n",
    "\n",
    "        #Tính toán số page\n",
    "        if no_candidate % 20 == 0:\n",
    "            no_page = no_candidate//20\n",
    "        else:\n",
    "            no_page = (no_candidate//20) + 1\n",
    "\n",
    "        #Khởi tạo các page\n",
    "        page_lst = [i for i in range(1,no_page +1)]\n",
    "        \n",
    "        #Nếu có nhiều hơn 1 page thì lần lượt click vào từng page\n",
    "        if len(page_lst) >1:\n",
    "            for page in page_lst:\n",
    "                page = driver.find_element(By.XPATH,f'//*[@id=\"tab-1\"]/div/div[3]/div[2]/div/ul/li[{page}]/a')\n",
    "                page.click()\n",
    "                pagesource = BeautifulSoup(driver.page_source)\n",
    "                candidate = pagesource.find_all('a',class_ = 'name')\n",
    "                for i in candidate:\n",
    "                    up_index = str(i).find('href=\"') + 6\n",
    "                    low_index = str(i).find('\" target=')\n",
    "                    candidate_url.append(str(i)[up_index:low_index])\n",
    "        \n",
    "        #Nếu chỉ có 1 page thì lấy thông tin luôn\n",
    "        else:\n",
    "            pagesource = BeautifulSoup(driver.page_source)\n",
    "            candidate = pagesource.find_all('a',class_ = 'name')\n",
    "            for i in candidate:\n",
    "                up_index = str(i).find('href=\"') + 6\n",
    "                low_index = str(i).find('\" target=')\n",
    "                candidate_url.append(str(i)[up_index:low_index])\n",
    "candidate_url = list(set(candidate_url))\n",
    "print('Get candidate url:', len(candidate_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New candidate start from 2023-02-06: 4\n"
     ]
    }
   ],
   "source": [
    "#Loại ra những ứng viên đã lấy về (so sánh id)\n",
    "old_values = recruitment_data['id'].values\n",
    "new_candidate = []\n",
    "for i in candidate_url:\n",
    "    if i[-17:-9] not in old_values:\n",
    "        new_candidate.append(i)\n",
    "print('New candidate start from 2023-02-06:', len(new_candidate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loại bỏ dấu trong tên\n",
    "s1 = u'ÀÁÂÃÈÉÊÌÍÒÓÔÕÙÚÝàáâãèéêìíòóôõùúýĂăĐđĨĩŨũƠơƯưẠạẢảẤấẦầẨẩẪẫẬậẮắẰằẲẳẴẵẶặẸẹẺẻẼẽẾếỀềỂểỄễỆệỈỉỊịỌọỎỏỐốỒồỔổỖỗỘộỚớỜờỞởỠỡỢợỤụỦủỨứỪừỬửỮữỰựỲỳỴỵỶỷỸỹ'\n",
    "s0 = u'AAAAEEEIIOOOOUUYaaaaeeeiioooouuyAaDdIiUuOoUuAaAaAaAaAaAaAaAaAaAaAaAaEeEeEeEeEeEeEeEeIiIiOoOoOoOoOoOoOoOoOoOoOoOoUuUuUuUuUuUuUuYyYyYyYy'\n",
    "def remove_accents(input_str):\n",
    "\ts = ''\n",
    "\tfor c in input_str:\n",
    "\t\tif c in s1:\n",
    "\t\t\ts += s0[s1.index(c)]\n",
    "\t\telse:\n",
    "\t\t\ts += c\n",
    "\treturn s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get data\n"
     ]
    }
   ],
   "source": [
    "#Tạo list rỗng để chứa các giá trị\n",
    "position = []\n",
    "name = []\n",
    "mail = []\n",
    "phone_number = []\n",
    "company = []\n",
    "id = []\n",
    "year = []\n",
    "month = []\n",
    "date = []\n",
    "\n",
    "#Lặp qua các đừng dẫn đến ứng viên mới để lấy ra thông tin\n",
    "for candidate in new_candidate:\n",
    "    driver.get(candidate)\n",
    "\n",
    "    candidate_position = driver.find_element(By.XPATH, '//*[@id=\"tab-1\"]/div/div/div/div[1]/nav/ol/li[2]').text\n",
    "    position.append(candidate_position)\n",
    "    if candidate_position.lower() == 'accountant' or candidate_position.lower() == 'customer service associate':\n",
    "        company.append('Genkin')\n",
    "    else:\n",
    "        company.append('Maido')\n",
    "\n",
    "    candidate_name = driver.find_element(By.XPATH, '//*[@id=\"tab-1\"]/div/div/div/div[4]/div[1]/div/div[2]/div[1]/div[1]/div[1]/ul/li[1]/p[2]').text\n",
    "    name.append(candidate_name)\n",
    "\n",
    "    apply_date = driver.find_element(By.XPATH, '//*[@id=\"tab-1\"]/div/div/div/div[3]/ul/li[3]/p[2]').text\n",
    "    d = apply_date.split('-')[0]\n",
    "    m = apply_date.split('-')[1]\n",
    "    y = apply_date.split('-')[2]\n",
    "    date.append(f'{y}-{m}-{d}')\n",
    "    month.append(m)\n",
    "    year.append(y)\n",
    "\n",
    "    #Nếu thông tin về sdt bị thiếu thì vị trí mail sẽ thay đổi. \n",
    "    if driver.find_element(By.XPATH, '//*[@id=\"tab-1\"]/div/div/div/div[4]/div[1]/div/div[2]/div[1]/div[2]/div/ul/li[1]/p[1]/strong').text.strip() == \"ĐTDĐ :\":\n",
    "        phone_number.append(driver.find_element(By.XPATH, '//*[@id=\"tab-1\"]/div/div/div/div[4]/div[1]/div/div[2]/div[1]/div[2]/div/ul/li[1]/p[2]').text)\n",
    "        mail.append(driver.find_element(By.XPATH, '//*[@id=\"tab-1\"]/div/div/div/div[4]/div[1]/div/div[2]/div[1]/div[2]/div/ul/li[2]/p[2]').text)\n",
    "    else:\n",
    "        phone_number.append(\"\")\n",
    "        mail.append(driver.find_element(By.XPATH, '//*[@id=\"tab-1\"]/div/div/div/div[4]/div[1]/div/div[2]/div[1]/div[2]/div/ul/li/p[2]').text)\n",
    "\n",
    "    #Truy xuất id từ link\n",
    "    candidate_id = candidate[-17:-9]\n",
    "    id.append(candidate_id)\n",
    "print('Get data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.DataFrame({'date':date,\n",
    "                  'month':month,\n",
    "                  'year':year,\n",
    "                  'company': company,\n",
    "                  'name':name,\n",
    "                  'mail':mail,\n",
    "                  'phone_number':phone_number,\n",
    "                  'position':position,\n",
    "                  'id':id\n",
    "                 }, columns = ['id','date','month','year','company','name','mail','phone_number','position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV downloaded\n"
     ]
    }
   ],
   "source": [
    "#Tải file cv về máy\n",
    "output_dir = '/Users/genkin/Downloads/CV_CRAWL_BOT/Job_Application_Crawl-main/CV_downloaded'\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "\n",
    "    candidate_name = df.iloc[i]['name']\n",
    "    candidate_id = df.iloc[i]['id']\n",
    "    candidate_position = df.iloc[i]['position']\n",
    "    apply_date = df.iloc[i]['date']\n",
    "    \n",
    "    download_url = f'https://careerbuilder.vn/vi/employers/popup/downloadresume?resume_id={candidate_id}'\n",
    "    driver.get(download_url)\n",
    "time.sleep(30)\n",
    "print('CV downloaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tạo ra 1 dictionary để đổi tên\n",
    "new_name = ['_'.join(position.upper().split(' ')) +\"(\"+date+')' for position,date in zip(df['position'],df['date'])]\n",
    "id = df['id'].values\n",
    "\n",
    "rename = {}\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "    rename[id[i]] = new_name[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 downloaded files have renamed\n"
     ]
    }
   ],
   "source": [
    "#Quét các file hiện có trong folder và đổi tên nếu match với dict đã tạo.\n",
    "upload_file_list = []\n",
    "file_name_dict = {}\n",
    "list_of_files = glob.glob('/Users/genkin/Downloads/CV_CRAWL_BOT/Job_Application_Crawl-main/CV_downloaded/*.pdf')\n",
    "for i in list_of_files:\n",
    "    index = str(i)[-12:-4]\n",
    "    if index in rename.keys():\n",
    "        new_name = str(i).replace(index,rename[index]).replace('.pdf','')\n",
    "\n",
    "        #Kiểm tra tên mới đã tồn tại hay chưa\n",
    "        if(not os.path.exists(new_name)):    \n",
    "            os.rename(i,new_name)\n",
    "        file_name = os.path.basename(new_name)\n",
    "        file_name_dict[index] = file_name\n",
    "        upload_file_list.append(new_name)\n",
    "print(f'{len(upload_file_list)} downloaded files have renamed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/genkin/Downloads/CV_CRAWL_BOT/Job_Application_Crawl-main/CV_downloaded/Tinh_Tinh_36BB574F.pdf',\n",
       " '/Users/genkin/Downloads/CV_CRAWL_BOT/Job_Application_Crawl-main/CV_downloaded/Nguyen_Phuoc_Thien_36BBA209.pdf',\n",
       " '/Users/genkin/Downloads/CV_CRAWL_BOT/Job_Application_Crawl-main/CV_downloaded/Chau_Le_Phuc_36BB8CC9.pdf',\n",
       " '/Users/genkin/Downloads/CV_CRAWL_BOT/Job_Application_Crawl-main/CV_downloaded/Ly_Huynh_To_Nhu_36BB42A2.pdf',\n",
       " '/Users/genkin/Downloads/CV_CRAWL_BOT/Job_Application_Crawl-main/CV_downloaded/Shunn_36BB8E6C.pdf',\n",
       " '/Users/genkin/Downloads/CV_CRAWL_BOT/Job_Application_Crawl-main/CV_downloaded/Chu_Thanh_Thien_36BCB285.pdf',\n",
       " '/Users/genkin/Downloads/CV_CRAWL_BOT/Job_Application_Crawl-main/CV_downloaded/nguyen_hoang_36BB3C34.pdf',\n",
       " '/Users/genkin/Downloads/CV_CRAWL_BOT/Job_Application_Crawl-main/CV_downloaded/Le_Thi_Hanh_Yen_36BCAF87.pdf',\n",
       " '/Users/genkin/Downloads/CV_CRAWL_BOT/Job_Application_Crawl-main/CV_downloaded/Nguyen_Chinh_36BBBF8A.pdf',\n",
       " '/Users/genkin/Downloads/CV_CRAWL_BOT/Job_Application_Crawl-main/CV_downloaded/Thanh_Huyen_Nguyen_Thi_36BB897A (1).pdf',\n",
       " '/Users/genkin/Downloads/CV_CRAWL_BOT/Job_Application_Crawl-main/CV_downloaded/Nguyen_Thi_Hoai_Thuong_36BBAA82.pdf',\n",
       " '/Users/genkin/Downloads/CV_CRAWL_BOT/Job_Application_Crawl-main/CV_downloaded/Nguyen_Kim_Yen_36BCB2A5.pdf',\n",
       " '/Users/genkin/Downloads/CV_CRAWL_BOT/Job_Application_Crawl-main/CV_downloaded/TRAN_QUYNH_VAN_THUY_36BCE96F.pdf',\n",
       " '/Users/genkin/Downloads/CV_CRAWL_BOT/Job_Application_Crawl-main/CV_downloaded/Nguyen_Hoang_Ngoc_36BB3813.pdf',\n",
       " '/Users/genkin/Downloads/CV_CRAWL_BOT/Job_Application_Crawl-main/CV_downloaded/Nguyen_Thi_Minh_Khoa_36BBA65D.pdf',\n",
       " '/Users/genkin/Downloads/CV_CRAWL_BOT/Job_Application_Crawl-main/CV_downloaded/Hien_My_36BB6938.pdf',\n",
       " '/Users/genkin/Downloads/CV_CRAWL_BOT/Job_Application_Crawl-main/CV_downloaded/Nguyen_Thanh_Mai_36BB6ED0.pdf',\n",
       " '/Users/genkin/Downloads/CV_CRAWL_BOT/Job_Application_Crawl-main/CV_downloaded/My_Hang_36BCC444.pdf',\n",
       " '/Users/genkin/Downloads/CV_CRAWL_BOT/Job_Application_Crawl-main/CV_downloaded/trang_minh_36BB61BE.pdf',\n",
       " '/Users/genkin/Downloads/CV_CRAWL_BOT/Job_Application_Crawl-main/CV_downloaded/Tran_Lien_Huong_36B068D5.pdf',\n",
       " '/Users/genkin/Downloads/CV_CRAWL_BOT/Job_Application_Crawl-main/CV_downloaded/Ngo_Viet_Xuan__Quynh_36BCF35C.pdf',\n",
       " '/Users/genkin/Downloads/CV_CRAWL_BOT/Job_Application_Crawl-main/CV_downloaded/Le_Ngoc_Tam_361D8D5D.pdf']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authorization done\n",
      "4 files uploaded\n"
     ]
    }
   ],
   "source": [
    "#Upload lên gg drive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "gauth = GoogleAuth()    \n",
    "gauth.LocalWebserverAuth()\n",
    "drive = GoogleDrive(gauth)\n",
    "print('Authorization done')\n",
    "targetDirID = '122XoM5A0SZWBqhFshmMTuem3Xfm-npuo'\n",
    " \n",
    "exist_file_list = drive.ListFile({'q': \"'{}' in parents and trashed=false\".format(targetDirID)}).GetList()\n",
    "\n",
    "#Nếu file bị trùng thì upload rồi xóa file cũ\n",
    "for upload_file in upload_file_list:\n",
    "\tif(not os.path.exists(upload_file)):\n",
    "\t\tcontinue\n",
    "\t\t\n",
    "\tfileName = os.path.basename(upload_file)\n",
    "\tfor file1 in exist_file_list:\n",
    "\t\tif file1['title'] == fileName:\n",
    "\t\t\tfile1.Delete()\n",
    "\t\t\n",
    "\tgfile = drive.CreateFile({'parents': [{'id': targetDirID}], 'title': fileName})\n",
    "\t# Read file and set it as the content of this instance.\n",
    "\tgfile.SetContentFile(upload_file)\n",
    "\tgfile.Upload() # Upload the file.\n",
    "print(f'{len(upload_file_list)} files uploaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lấy ra các tên + đường dẫn các file hiện có trong folder trên drive\n",
    "name_lst = []\n",
    "cv_link = []\n",
    "files = drive.ListFile({\"q\": \"'\" + targetDirID + \"' in parents and mimeType!='application/vnd.google-apps.folder'\"}).GetList()\n",
    "for file in files:\n",
    "    keys = file.keys()\n",
    "    if file['shared'] and 'alternateLink' in keys:\n",
    "        link = file['alternateLink']\n",
    "    else:\n",
    "        link = 'No Link Available. Check your sharing settings.'\n",
    "    name = file['title']\n",
    "    name_lst.append(name)\n",
    "    cv_link.append(link)\n",
    "    \n",
    "cv_df = pd.DataFrame({'file_name':name_lst,'cv':cv_link}, columns=['file_name','cv'])\n",
    "cv_df.drop_duplicates(subset='file_name', keep=\"last\",inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 new data to append\n"
     ]
    }
   ],
   "source": [
    "#Nối link cv với dataframe chứa thông tin\n",
    "df['file_name'] = [file_name_dict[i] for i in df['id']]\n",
    "data = pd.merge(df,cv_df,how='left')\n",
    "data.drop_duplicates(inplace = True)\n",
    "print(f'{len(data)} new data to append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Làm sạch/ thêm 1 vài cột cần thiết\n",
    "data['source'] = ['CareerBuilder']*len(data)\n",
    "data['graduated'] = ['']*len(data)\n",
    "data['note'] = ['']*len(data)\n",
    "data['name'] = [str(i).upper() for i in data['name']]\n",
    "data['company'] = [str(i).upper() for i in data['company']]\n",
    "data['position'] = [str(i).upper() for i in data['position']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Ghi lên gg sheet\n",
    "append_index = \"A\" + str(len(recruitment_data)+2)\n",
    "\n",
    "if len(data) > 0:\n",
    "    wks.set_dataframe(data[['id','company','year','month','date','name','source','position','phone_number','mail','cv','graduated','note']], start=append_index, copy_head=False)\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
